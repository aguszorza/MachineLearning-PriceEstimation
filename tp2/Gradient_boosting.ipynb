{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obtener_rmse(col_true, col_pred):\n",
    "    return mean_squared_error(col_true, col_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = pd.read_csv('../../set_datos_propiedades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = propiedades.loc[(propiedades.price_aprox_usd.notnull()) & (propiedades.superficie.notnull()),\\\n",
    "                             ['place_name_encoded', 'property_type_encoded','price_aprox_usd','superficie',\\\n",
    "                             'Year','Month','seguridad','aire','gimnasio','cochera','pileta']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','place_name_encoded','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = propiedades.loc[(propiedades.Year >= 2016) &((propiedades.Year < 2017) | (propiedades.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = propiedades.loc[(propiedades.Year == 2017) & (propiedades.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 49.59 % , error = 263717.911261235\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingRegressor()\n",
    "gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "precision = gradient.score(set_pruebas.loc[:,columnas], set_pruebas.price_aprox_usd) * 100\n",
    "error = obtener_rmse(set_pruebas.price_aprox_usd, set_pruebas.resultado)\n",
    "print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora que tenemos una intuicion, probamos cambiando los parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','place_name_encoded','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = propiedades.loc[(propiedades.Year >= 2016) &((propiedades.Year < 2017) | (propiedades.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = propiedades.loc[(propiedades.Year == 2017) & (propiedades.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "loss = ['ls', 'lad', 'huber', 'quantile']\n",
    "n_estimators = [300, 500, 1000, 2000]\n",
    "\n",
    "for l in loss:\n",
    "    for n in n_estimators:\n",
    "        gradient = GradientBoostingRegressor(loss = l, n_estimators = n)\n",
    "        gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "        set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "        precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.loc[:,'price_aprox_usd']) * 100\n",
    "        error = obtener_rmse(set_pruebas.price_aprox_usd, set_pruebas.resultado)\n",
    "        res.append((l, n, precision, error))\n",
    "        print(l,' - ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = ls, n_estimators = 300, precision = 55.15 % , error = 248737.31486991755\n",
      "Loss = ls, n_estimators = 500, precision = 57.50 % , error = 242135.99581654233\n",
      "Loss = ls, n_estimators = 1000, precision = 60.48 % , error = 233486.84277362804\n",
      "Loss = ls, n_estimators = 2000, precision = 62.91 % , error = 226215.10776356\n",
      "Loss = lad, n_estimators = 300, precision = 47.35 % , error = 269518.0659149018\n",
      "Loss = lad, n_estimators = 500, precision = 49.66 % , error = 263524.37826822215\n",
      "Loss = lad, n_estimators = 1000, precision = 50.67 % , error = 260861.96525934708\n",
      "Loss = lad, n_estimators = 2000, precision = 51.67 % , error = 258216.88529997237\n",
      "Loss = huber, n_estimators = 300, precision = 51.41 % , error = 258917.110961643\n",
      "Loss = huber, n_estimators = 500, precision = 46.40 % , error = 271928.52928042517\n",
      "Loss = huber, n_estimators = 1000, precision = 47.81 % , error = 268320.914070446\n",
      "Loss = huber, n_estimators = 2000, precision = 48.50 % , error = 266545.7580620435\n",
      "Loss = quantile, n_estimators = 300, precision = 8.29 % , error = 355705.3713396\n",
      "Loss = quantile, n_estimators = 500, precision = 8.92 % , error = 354483.66145246977\n",
      "Loss = quantile, n_estimators = 1000, precision = 10.78 % , error = 350830.90353463416\n",
      "Loss = quantile, n_estimators = 2000, precision = 10.17 % , error = 352031.75349483587\n"
     ]
    }
   ],
   "source": [
    "for r in res\n",
    "\n",
    "    print(\"Loss = {}, n_estimators = {}, precision = {:.2f} % , error = {}\".format(r[0],r[1],r[2],r[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor precision = Loss = ls, n_estimators = 2000, precision = 62.91 % , error = 226215.10776356\n",
      "Menor error = Loss = ls, n_estimators = 2000, precision = 62.91 % , error = 226215.10776356\n"
     ]
    }
   ],
   "source": [
    "min_error = float('inf')\n",
    "max_precision = 0\n",
    "tupla_min_error = ()\n",
    "tupla_max_precision = ()\n",
    "for r in res:\n",
    "    if r[3] < min_error:\n",
    "        min_error = r[3]\n",
    "        tupla_min_error = r\n",
    "    if abs(r[2]) > max_precision:\n",
    "        max_precision = r[2]\n",
    "        tupla_max_precision = r\n",
    "        \n",
    "print(\"Mayor precision = Loss = {}, n_estimators = {}, precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_max_precision[0],tupla_max_precision[1],tupla_max_precision[2],tupla_max_precision[3]))\n",
    "print(\"Menor error = Loss = {}, n_estimators = {}, precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_min_error[0],tupla_min_error[1],tupla_min_error[2],tupla_min_error[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usamos ls como loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','place_name_encoded','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = propiedades.loc[(propiedades.Year >= 2016) &((propiedades.Year < 2017) | (propiedades.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = propiedades.loc[(propiedades.Year == 2017) & (propiedades.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = 'ls'\n",
    "n_est = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n",
      "Precision = 62.91 % , error = 226215.10776355996\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingRegressor(loss = loss, n_estimators = n_est, warm_start = True)\n",
    "for i in range(10):\n",
    "    gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "    set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "    precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "    error = obtener_rmse(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "    print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No se obtuvo mejora utilizando warm_start = True, por lo que realizar varias iteraciones con los mismos datos no mejorará la precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 68.10 % , error = 209782.67862516703\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingRegressor(loss = loss, n_estimators = 10000, warm_start = True)\n",
    "gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "error = obtener_rmse(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.000000e+04\n",
       "mean     2.645389e+05\n",
       "std      2.998174e+05\n",
       "min      5.833006e+02\n",
       "25%      1.081312e+05\n",
       "50%      1.716801e+05\n",
       "75%      2.996141e+05\n",
       "max      6.980550e+06\n",
       "Name: resultado, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_pruebas.resultado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,\"resultado\"].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209673.22218335391"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtener_rmse(set_pruebas.price_aprox_usd,set_pruebas.resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vario la profundidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','place_name_encoded','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = propiedades.loc[(propiedades.Year >= 2016) &((propiedades.Year < 2017) | (propiedades.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = propiedades.loc[(propiedades.Year == 2017) & (propiedades.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = [1, 3, 5, 10, 20]\n",
    "learning = [0.1, 0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for d in depth:\n",
    "    for l in learning:\n",
    "        gradient = GradientBoostingRegressor(loss = \"ls\", max_depth = d, learning_rate = l)\n",
    "        gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "        set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "        precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "        error = obtener_rmse(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "        res.append((d, l, precision, error))\n",
    "        print(d, \" - \", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los casos faltantes de profundidad 20 se descartaron debido al elevado tiempo de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1, learning_rate = 0.1, precision = 36.24 % , error = 296585.3952956776\n",
      "max_depth = 1, learning_rate = 0.3, precision = 38.77 % , error = 290645.3508711553\n",
      "max_depth = 1, learning_rate = 0.5, precision = 39.96 % , error = 287808.51835432526\n",
      "max_depth = 1, learning_rate = 0.7, precision = 40.81 % , error = 285757.0809324506\n",
      "max_depth = 3, learning_rate = 0.1, precision = 49.59 % , error = 263717.91126123496\n",
      "max_depth = 3, learning_rate = 0.3, precision = 55.44 % , error = 247942.04557652943\n",
      "max_depth = 3, learning_rate = 0.5, precision = 57.41 % , error = 242387.34201665278\n",
      "max_depth = 3, learning_rate = 0.7, precision = 58.25 % , error = 239982.7016595514\n",
      "max_depth = 5, learning_rate = 0.1, precision = 58.86 % , error = 238243.53268510482\n",
      "max_depth = 5, learning_rate = 0.3, precision = 65.91 % , error = 216863.74408280538\n",
      "max_depth = 5, learning_rate = 0.5, precision = 68.59 % , error = 208176.2512388309\n",
      "max_depth = 5, learning_rate = 0.7, precision = 69.94 % , error = 203652.462357837\n",
      "max_depth = 10, learning_rate = 0.1, precision = 77.87 % , error = 174726.54117536245\n",
      "max_depth = 10, learning_rate = 0.3, precision = 84.78 % , error = 144918.6096853223\n",
      "max_depth = 10, learning_rate = 0.5, precision = 87.60 % , error = 130773.1434687948\n",
      "max_depth = 10, learning_rate = 0.7, precision = 88.59 % , error = 125458.61787344264\n",
      "max_depth = 20, learning_rate = 0.1, precision = 91.04 % , error = 111203.91908671668\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(\"max_depth = {}, learning_rate = {}, precision = {:.2f} % , error = {}\".format(r[0],r[1],r[2],r[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tomo un millon de estimadores para ver cuanto mejora la precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','place_name_encoded','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = propiedades.loc[(propiedades.Year >= 2016) &((propiedades.Year < 2017) | (propiedades.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = propiedades.loc[(propiedades.Year == 2017) & (propiedades.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 90.58 % , error = 114027.97059902015\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingRegressor(loss = loss, n_estimators = 2000, learning_rate= 0.1, max_depth = 10)\n",
    "gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "error = obtener_rmse(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.000000e+04\n",
       "mean     2.657068e+05\n",
       "std      3.517090e+05\n",
       "min     -1.695101e+04\n",
       "25%      9.974896e+04\n",
       "50%      1.583140e+05\n",
       "75%      2.900442e+05\n",
       "max      1.109959e+07\n",
       "Name: resultado, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_pruebas.resultado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,\"resultado\"].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.000000e+04\n",
       "mean     2.657085e+05\n",
       "std      3.517077e+05\n",
       "min      9.234466e+03\n",
       "25%      9.974896e+04\n",
       "50%      1.583140e+05\n",
       "75%      2.900442e+05\n",
       "max      1.109959e+07\n",
       "Name: resultado, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_pruebas.resultado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114027.37597125868"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtener_rmse(set_pruebas.price_aprox_usd,set_pruebas.resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculo con los verdaderos datos a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analizar = pd.read_csv(\"../properati_dataset_modificado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analizar.loc[:,'price_usd'] = analizar.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.416600e+04\n",
       "mean     2.373848e+05\n",
       "std      3.434490e+05\n",
       "min     -5.127444e+05\n",
       "25%      1.054205e+05\n",
       "50%      1.572446e+05\n",
       "75%      2.630949e+05\n",
       "max      2.771613e+07\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar.price_usd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Las predicciones con precio negativo las convierto en valores positivos\n",
    "analizar.loc[:,'price_usd'] = analizar.loc[:,\"price_usd\"].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.416600e+04\n",
       "mean     2.377970e+05\n",
       "std      3.431637e+05\n",
       "min      1.270784e+02\n",
       "25%      1.055294e+05\n",
       "50%      1.573691e+05\n",
       "75%      2.632307e+05\n",
       "max      2.771613e+07\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar.price_usd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultado = analizar.loc[:,['id','price_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultado.to_csv('resultados/Gradient_boosting_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora uso lat y lon en lugar de place name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = propiedades.loc[(propiedades.price_aprox_usd.notnull()) & (propiedades.superficie.notnull())\\\n",
    "                              & (propiedades.lat.notnull()) & (propiedades.lon.notnull()),\\\n",
    "                             ['lat', 'lon', 'property_type_encoded','price_aprox_usd','superficie',\\\n",
    "                             'Year','Month','seguridad','aire','gimnasio','cochera','pileta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','lat', 'lon','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = propiedades.loc[(propiedades.Year >= 2016) &((propiedades.Year < 2017) | (propiedades.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = propiedades.loc[(propiedades.Year == 2017) & (propiedades.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 55.02 % , error = 52075495716.7\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingRegressor()\n",
    "gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "precision = gradient.score(set_pruebas.loc[:,columnas], set_pruebas.price_aprox_usd) * 100\n",
    "error = mean_squared_error(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = ['ls', 'lad', 'huber', 'quantile']\n",
    "n_estimators = [300, 500, 1000, 2000, 5000]\n",
    "d = 3\n",
    "lr = 0.1\n",
    "\n",
    "for l in loss:\n",
    "    for n in n_estimators: \n",
    "        gradient = GradientBoostingRegressor(loss = l, n_estimators = n, max_depth = d, learning_rate = lr)\n",
    "        gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "        set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "        precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.loc[:,'price_aprox_usd']) * 100\n",
    "        error = mean_squared_error(set_pruebas.price_aprox_usd, set_pruebas.resultado)\n",
    "        res.append((l, n, d, lr, precision, error))\n",
    "        print(l,' - ', n, '-', d, '-', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor precision = Loss = ls, n_estimators = 5000, max_depth = 3, learning_rate = 0.1 precision = 78.73 % , error = 24626934120.9\n",
      "Menor error = Loss = ls, n_estimators = 5000, max_depth = 3, learning_rate = 0.1 precision = 78.73 % , error = 24626934120.9\n"
     ]
    }
   ],
   "source": [
    "min_error = float('inf')\n",
    "max_precision = 0\n",
    "tupla_min_error = ()\n",
    "tupla_max_precision = ()\n",
    "for r in res:\n",
    "    if r[5] < min_error:\n",
    "        min_error = r[5]\n",
    "        tupla_min_error = r\n",
    "    if abs(r[4]) > max_precision:\n",
    "        max_precision = r[4]\n",
    "        tupla_max_precision = r\n",
    "        \n",
    "print(\"Mayor precision = Loss = {}, n_estimators = {}, max_depth = {}, learning_rate = {} precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_max_precision[0],tupla_max_precision[1],tupla_max_precision[2],tupla_max_precision[3], tupla_max_precision[4], tupla_max_precision[5]))\n",
    "print(\"Menor error = Loss = {}, n_estimators = {}, max_depth = {}, learning_rate = {} precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_min_error[0],tupla_min_error[1],tupla_min_error[2],tupla_min_error[3], tupla_min_error[4], tupla_min_error[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = 'ls'\n",
    "n = 100 #Utilizo 100 para que sea mas rapido\n",
    "depth = [3, 5, 10, 20]\n",
    "learning = [0.3, 0.5, 0.7]\n",
    "for d in depth:\n",
    "    for lr in learning:\n",
    "        gradient = GradientBoostingRegressor(loss = l, n_estimators = n, max_depth = d, learning_rate = lr)\n",
    "        gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "        set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "        precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.loc[:,'price_aprox_usd']) * 100\n",
    "        error = mean_squared_error(set_pruebas.price_aprox_usd, set_pruebas.resultado)\n",
    "        res.append((l, n, d, lr, precision, error))\n",
    "        print(l,' - ', n, '-', d, '-', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = ls, n_estimators = 300, max_depth = 3, learning_rate = 0.1 precision = 60.32 % , error = 45940935462.6\n",
      "Loss = ls, n_estimators = 500, max_depth = 3, learning_rate = 0.1 precision = 62.87 % , error = 42994100031.3\n",
      "Loss = ls, n_estimators = 1000, max_depth = 3, learning_rate = 0.1 precision = 69.18 % , error = 35688017721.5\n",
      "Loss = ls, n_estimators = 2000, max_depth = 3, learning_rate = 0.1 precision = 73.62 % , error = 30540892887.9\n",
      "Loss = ls, n_estimators = 5000, max_depth = 3, learning_rate = 0.1 precision = 78.73 % , error = 24626934120.9\n",
      "Loss = lad, n_estimators = 300, max_depth = 3, learning_rate = 0.1 precision = 51.36 % , error = 56312231384.9\n",
      "Loss = lad, n_estimators = 500, max_depth = 3, learning_rate = 0.1 precision = 52.89 % , error = 54551045303.2\n",
      "Loss = lad, n_estimators = 1000, max_depth = 3, learning_rate = 0.1 precision = 53.92 % , error = 53354819402.9\n",
      "Loss = lad, n_estimators = 2000, max_depth = 3, learning_rate = 0.1 precision = 54.97 % , error = 52137025108.6\n",
      "Loss = lad, n_estimators = 5000, max_depth = 3, learning_rate = 0.1 precision = 53.75 % , error = 53555353192.1\n",
      "Loss = huber, n_estimators = 300, max_depth = 3, learning_rate = 0.1 precision = 54.91 % , error = 52206040465.9\n",
      "Loss = huber, n_estimators = 500, max_depth = 3, learning_rate = 0.1 precision = 56.15 % , error = 50776101315.6\n",
      "Loss = huber, n_estimators = 1000, max_depth = 3, learning_rate = 0.1 precision = 58.46 % , error = 48099275494.1\n",
      "Loss = huber, n_estimators = 2000, max_depth = 3, learning_rate = 0.1 precision = 59.67 % , error = 46695448962.5\n",
      "Loss = huber, n_estimators = 5000, max_depth = 3, learning_rate = 0.1 precision = 61.59 % , error = 44476772457.2\n",
      "Loss = quantile, n_estimators = 300, max_depth = 3, learning_rate = 0.1 precision = 22.19 % , error = 90086335152.7\n",
      "Loss = quantile, n_estimators = 500, max_depth = 3, learning_rate = 0.1 precision = 24.44 % , error = 87487524144.6\n",
      "Loss = quantile, n_estimators = 1000, max_depth = 3, learning_rate = 0.1 precision = 18.53 % , error = 94329324234.1\n",
      "Loss = quantile, n_estimators = 2000, max_depth = 3, learning_rate = 0.1 precision = 24.45 % , error = 87476384105.3\n",
      "Loss = quantile, n_estimators = 5000, max_depth = 3, learning_rate = 0.1 precision = 24.43 % , error = 87497691083.1\n",
      "Loss = ls, n_estimators = 100, max_depth = 3, learning_rate = 0.3 precision = 60.73 % , error = 45469235872.7\n",
      "Loss = ls, n_estimators = 100, max_depth = 3, learning_rate = 0.5 precision = 63.97 % , error = 41721876310.4\n",
      "Loss = ls, n_estimators = 100, max_depth = 3, learning_rate = 0.7 precision = 63.74 % , error = 41978102525.9\n",
      "Loss = ls, n_estimators = 100, max_depth = 5, learning_rate = 0.3 precision = 75.51 % , error = 28355917714.0\n",
      "Loss = ls, n_estimators = 100, max_depth = 5, learning_rate = 0.5 precision = 76.31 % , error = 27431320817.3\n",
      "Loss = ls, n_estimators = 100, max_depth = 5, learning_rate = 0.7 precision = 76.85 % , error = 26806303703.5\n",
      "Loss = ls, n_estimators = 100, max_depth = 10, learning_rate = 0.3 precision = 95.57 % , error = 5131997010.15\n",
      "Loss = ls, n_estimators = 100, max_depth = 10, learning_rate = 0.5 precision = 95.74 % , error = 4929705202.07\n",
      "Loss = ls, n_estimators = 100, max_depth = 10, learning_rate = 0.7 precision = 96.18 % , error = 4421874076.55\n",
      "Loss = ls, n_estimators = 100, max_depth = 20, learning_rate = 0.3 precision = 98.39 % , error = 1861890273.38\n",
      "Loss = ls, n_estimators = 100, max_depth = 20, learning_rate = 0.5 precision = 98.36 % , error = 1894393964.32\n",
      "Loss = ls, n_estimators = 100, max_depth = 20, learning_rate = 0.7 precision = 98.37 % , error = 1892180851.05\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(\"Loss = {}, n_estimators = {}, max_depth = {}, learning_rate = {} precision = {:.2f} % , error = {}\"\\\n",
    "          .format(r[0],r[1],r[2],r[3], r[4], r[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor precision = Loss = ls, n_estimators = 100, max_depth = 20, learning_rate = 0.3 precision = 98.39 % , error = 1861890273.38\n",
      "Menor error = Loss = ls, n_estimators = 100, max_depth = 20, learning_rate = 0.3 precision = 98.39 % , error = 1861890273.38\n"
     ]
    }
   ],
   "source": [
    "min_error = float('inf')\n",
    "max_precision = 0\n",
    "tupla_min_error = ()\n",
    "tupla_max_precision = ()\n",
    "for r in res:\n",
    "    if r[5] < min_error:\n",
    "        min_error = r[5]\n",
    "        tupla_min_error = r\n",
    "    if abs(r[4]) > max_precision:\n",
    "        max_precision = r[4]\n",
    "        tupla_max_precision = r\n",
    "        \n",
    "print(\"Mayor precision = Loss = {}, n_estimators = {}, max_depth = {}, learning_rate = {} precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_max_precision[0],tupla_max_precision[1],tupla_max_precision[2],tupla_max_precision[3], tupla_max_precision[4], tupla_max_precision[5]))\n",
    "print(\"Menor error = Loss = {}, n_estimators = {}, max_depth = {}, learning_rate = {} precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_min_error[0],tupla_min_error[1],tupla_min_error[2],tupla_min_error[3], tupla_min_error[4], tupla_min_error[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.408854513852148"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient.score(set_entrenamiento_datos,set_entrenamiento_resultado) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculo con los verdaderos datos a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analizar = pd.read_csv(\"../properati_dataset_modificado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analizar.loc[:,'price_usd'] = analizar.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.416600e+04\n",
       "mean     2.453845e+05\n",
       "std      5.195269e+05\n",
       "min     -1.403059e+04\n",
       "25%      1.001735e+05\n",
       "50%      1.532872e+05\n",
       "75%      2.590019e+05\n",
       "max      4.682592e+07\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar.price_usd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Las predicciones con precio negativo las convierto en valores positivos\n",
    "analizar.loc[:,'price_usd'] = analizar.loc[:,\"price_usd\"].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.416600e+04\n",
       "mean     2.453879e+05\n",
       "std      5.195253e+05\n",
       "min      2.138798e+03\n",
       "25%      1.001735e+05\n",
       "50%      1.532872e+05\n",
       "75%      2.590019e+05\n",
       "max      4.682592e+07\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar.price_usd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultado = analizar.loc[:,['id','price_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultado.to_csv('resultados/Gradient_boosting_latlon.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando Grid Search y Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = pd.read_csv('../../set_datos_propiedades.csv')\n",
    "\n",
    "propiedades = propiedades.loc[(propiedades.price_aprox_usd.notnull()) & (propiedades.superficie.notnull())\\\n",
    "                              & (propiedades.lat.notnull()) & (propiedades.lon.notnull()) & (propiedades.Year >=2016)]\n",
    "\n",
    "columnas = ['superficie','lat', 'lon','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']\n",
    "\n",
    "set_entrenamiento_datos = propiedades.loc[:,columnas]\n",
    "set_entrenamiento_resultado = propiedades.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parametros\n",
    "\n",
    "loss = ['ls', 'lad', 'huber', 'quantile']\n",
    "n_estimators = [10,20,50,100]\n",
    "learning = [0.3, 0.5, 0.7]\n",
    "\n",
    "parametros = {\"loss\" : loss, \"n_estimators\" : n_estimators, \"learning_rate\" : learning}\n",
    "\n",
    "iteraciones_cross_validation = 15\n",
    "gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 21:32:45 --- 04:47:13 \n",
      " Precision: 75.65 \n",
      " Parametros = {'learning_rate': 0.5, 'loss': 'ls', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "inicio = time.strftime(\"%X\")\n",
    "\n",
    "grid = GridSearchCV( estimator = gb, param_grid = parametros, n_jobs = 2, cv = iteraciones_cross_validation)\n",
    "\n",
    "grid.fit(set_entrenamiento_datos, set_entrenamiento_resultado)\n",
    "\n",
    "score = grid.best_score_ * 100\n",
    "mejores_parametros = grid.best_params_\n",
    "fin = time.strftime(\"%X\")\n",
    "\n",
    "print(\"Tiempo: {} --- {} \\n Precision: {:.2f} \\n Parametros = {}\".format(inicio,fin,score,mejores_parametros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algoritmos/gradient_boosting.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar = pd.read_csv(\"../properati_dataset_modificado.csv\")\n",
    "\n",
    "analizar.loc[:,'price_usd'] = analizar.loc[:,columnas].apply(lambda x: grid.predict(x)[0],axis = 1)\n",
    "\n",
    "resultado = analizar.loc[:,['id','price_usd']]\n",
    "\n",
    "resultado.to_csv('resultados/Gradient_Boosting_GridSearch.csv', index = False)\n",
    "\n",
    "joblib.dump(grid, 'algoritmos/gradient_boosting.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = pd.read_csv('../../set_datos_propiedades.csv')\n",
    "\n",
    "propiedades = propiedades.loc[(propiedades.price_aprox_usd.notnull()) & (propiedades.superficie.notnull())\\\n",
    "                              & (propiedades.lat.notnull()) & (propiedades.lon.notnull()) & (propiedades.Year >=2016)]\n",
    "\n",
    "columnas = ['superficie','lat', 'lon','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']\n",
    "\n",
    "set_pruebas = analizar = pd.read_csv(\"../properati_dataset_modificado.csv\")\n",
    "set_pruebas.loc[:,'price_usd'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cant = 10\n",
    "\n",
    "for i in range(cant):\n",
    "    datos = propiedades.sample(frac = 0.4)\n",
    "    set_entrenamiento_datos = datos.loc[:,columnas]\n",
    "    set_entrenamiento_resultado = datos.loc[:,'price_aprox_usd']\n",
    "    \n",
    "    gb = GradientBoostingRegressor(loss = 'ls', n_estimators = 100, learning_rate = 0.5)\n",
    "    \n",
    "    gb.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "    set_pruebas.loc[:,'res'] = set_pruebas.loc[:,columnas].apply(lambda x: gb.predict(x)[0],axis = 1)\n",
    "    set_pruebas.loc[:,'price_usd'] = set_pruebas.loc[:,'price_usd'] + set_pruebas.loc[:,'res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_pruebas.loc[:,'price_usd'] = set_pruebas.loc[:,'price_usd'] / cant\n",
    "\n",
    "resultado = set_pruebas.loc[:,['id','price_usd']]\n",
    "\n",
    "resultado.to_csv('resultados/Gradient_Boosting_Cross_Validation.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando SVD con varias dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = pd.read_csv('../../set_datos_propiedades.csv')\n",
    "\n",
    "sup_min = 10\n",
    "sup_max = 300\n",
    "lat_min = -35\n",
    "lat_max = -34\n",
    "lon_min = -59\n",
    "lon_max = -58\n",
    "precio_min = 30000\n",
    "precio_max = 3000000\n",
    "\n",
    "propiedades = propiedades.loc[(propiedades.price_aprox_usd.notnull()) & (propiedades.superficie.notnull())\\\n",
    "                              & (propiedades.lat.notnull()) & (propiedades.lon.notnull()) & (propiedades.Year >=2016)\\\n",
    "                        & (propiedades.price_aprox_usd <= precio_max) & (propiedades.price_aprox_usd >= precio_min) &\\\n",
    "                         (propiedades.superficie <= sup_max) & (propiedades.superficie >= sup_min) &\\\n",
    "                      (propiedades.lat <= lat_max) & (propiedades.lat >= lat_min) &\\\n",
    "                       (propiedades.lon <= lon_max) & (propiedades.lon >= lon_min),:]\n",
    "\n",
    "columnas = ['superficie','lat', 'lon','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim = 2, Precision = 38.65, error = 7994080987.32, digitos = 10\n",
      "Dim = 3, Precision = 49.58, error = 6569938220.99, digitos = 10\n",
      "Dim = 4, Precision = 52.68, error = 6166630279.46, digitos = 10\n",
      "Dim = 5, Precision = 53.15, error = 6105555076.22, digitos = 10\n",
      "Dim = 6, Precision = 53.59, error = 6047299699.84, digitos = 10\n",
      "Dim = 7, Precision = 53.71, error = 6032644927.89, digitos = 10\n",
      "Dim = 8, Precision = 53.95, error = 6001328505.42, digitos = 10\n"
     ]
    }
   ],
   "source": [
    "X = propiedades.loc[:,columnas]\n",
    "y = propiedades.loc[:,'price_aprox_usd']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "for i in range(2,len(columnas)):\n",
    "    svd = TruncatedSVD(n_components = i)\n",
    "    datos = svd.fit_transform(X_train)\n",
    "    test = svd.transform(X_test)\n",
    "    \n",
    "    gradient = GradientBoostingRegressor()\n",
    "    gradient.fit(datos,y_train)\n",
    "    precision = gradient.score(test,y_test) * 100\n",
    "    error = mean_squared_error(gradient.predict(test),y_test)\n",
    "    \n",
    "    print(\"Dim = {}, Precision = {:.2f}, error = {}, digitos = {}\".\\\n",
    "                  format(i,precision,error,len(str(int(round(error,0))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_pruebas = analizar = pd.read_csv(\"../properati_dataset_modificado.csv\")\n",
    "\n",
    "svd = TruncatedSVD(n_components = 8)\n",
    "datos = svd.fit_transform(propiedades.loc[:,columnas])\n",
    "test = svd.transform(set_pruebas.loc[:,columnas])\n",
    "\n",
    "gradient = GradientBoostingRegressor()\n",
    "gradient.fit(datos,propiedades.loc[:,'price_aprox_usd'])\n",
    "set_pruebas.loc[:,'price_usd'] = gradient.predict(test)\n",
    "\n",
    "resultado = set_pruebas.loc[:,['id','price_usd']]\n",
    "resultado.to_csv('resultados/Gradient_Boosting_SVD.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregando el resultado de SVD dimension 2 al Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propiedades = pd.read_csv('../../set_datos_propiedades.csv')\n",
    "\n",
    "sup_min = 10\n",
    "sup_max = 300\n",
    "lat_min = -35\n",
    "lat_max = -34\n",
    "lon_min = -59\n",
    "lon_max = -58\n",
    "precio_min = 30000\n",
    "precio_max = 3000000\n",
    "\n",
    "propiedades = propiedades.loc[(propiedades.price_aprox_usd.notnull()) & (propiedades.superficie.notnull())\\\n",
    "                              & (propiedades.lat.notnull()) & (propiedades.lon.notnull()) & (propiedades.Year >=2016)\\\n",
    "                        & (propiedades.price_aprox_usd <= precio_max) & (propiedades.price_aprox_usd >= precio_min) &\\\n",
    "                         (propiedades.superficie <= sup_max) & (propiedades.superficie >= sup_min) &\\\n",
    "                      (propiedades.lat <= lat_max) & (propiedades.lat >= lat_min) &\\\n",
    "                       (propiedades.lon <= lon_max) & (propiedades.lon >= lon_min),:]\n",
    "\n",
    "prop = propiedades.loc[(propiedades.Year >= 2016), :]\n",
    "\n",
    "columnas = ['superficie','lat', 'lon','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "columnas_precio = columnas + ['price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_entrenamiento = prop.loc[(prop.Year >= 2016) &((prop.Year < 2017) | (prop.Month < 6))\\\n",
    "                                    ,columnas_precio]\n",
    "set_pruebas = prop.loc[(prop.Year == 2017) & (prop.Month == 6),columnas_precio].head(20000)\n",
    "\n",
    "set_entrenamiento_datos = set_entrenamiento.loc[:,columnas]\n",
    "set_entrenamiento_resultado = set_entrenamiento.loc[:,'price_aprox_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD()\n",
    "resultado = svd.fit_transform(set_entrenamiento_datos)\n",
    "resultado = pd.DataFrame(resultado)\n",
    "pruebas = svd.transform(set_pruebas.loc[:,columnas])\n",
    "pruebas = pd.DataFrame(pruebas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    334935.000000\n",
       "mean         95.098990\n",
       "std          24.394078\n",
       "min          52.920358\n",
       "25%          75.951302\n",
       "50%          88.599928\n",
       "75%         110.070518\n",
       "max         157.152840\n",
       "Name: SVD 1, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento_datos.reset_index(drop = True, inplace = True)\n",
    "set_entrenamiento_datos.loc[:,'SVD 1'] = resultado.loc[:,0]\n",
    "set_entrenamiento_datos.loc[:,'SVD 2'] = resultado.loc[:,1]\n",
    "set_entrenamiento_datos['SVD 1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20000.000000\n",
       "mean        96.581427\n",
       "std         24.831401\n",
       "min         52.920358\n",
       "25%         76.701836\n",
       "50%         90.073607\n",
       "75%        112.379512\n",
       "max        157.152840\n",
       "Name: SVD 1, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_pruebas.reset_index(drop = True, inplace = True)\n",
    "set_pruebas.loc[:,'SVD 1'] = pruebas.loc[:,0]\n",
    "set_pruebas.loc[:,'SVD 2'] = pruebas.loc[:,1]\n",
    "set_pruebas['SVD 1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = columnas + ['SVD 1', 'SVD 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 70.33 % , error = 4129998298.08\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingRegressor()\n",
    "gradient.fit(set_entrenamiento_datos, set_entrenamiento_resultado)\n",
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "error = mean_squared_error(set_pruebas.price_aprox_usd, set_pruebas.resultado)\n",
    "print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = ['ls', 'lad', 'huber', 'quantile']\n",
    "n_estimators = [300, 500, 1000, 2000, 5000]\n",
    "learning = [0.3, 0.5, 0.7]\n",
    "\n",
    "for l in loss:\n",
    "    for n in n_estimators:        \n",
    "        for lr in learning:\n",
    "            gradient = GradientBoostingRegressor(loss = l, n_estimators = n, learning_rate = lr)\n",
    "            gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "            set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply\\\n",
    "                    (lambda x: gradient.predict([x])[0],axis = 1)\n",
    "            precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "            error = mean_squared_error(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "            res.append((l, n, lr, precision, error))\n",
    "            print(l,' - ', n, '-', lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los resultados faltantes de quantile se descartaron debido al elevado tiempo de entrenamiento y los resultados pocos precisos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = ls, n_estimators = 300, learning_rate = 0.3, precision = 78.36 % , error = 3011932448.2\n",
      "loss = ls, n_estimators = 300, learning_rate = 0.5, precision = 80.18 % , error = 2758627822.77\n",
      "loss = ls, n_estimators = 300, learning_rate = 0.7, precision = 81.56 % , error = 2567349947.78\n",
      "loss = ls, n_estimators = 500, learning_rate = 0.3, precision = 80.55 % , error = 2707972187.36\n",
      "loss = ls, n_estimators = 500, learning_rate = 0.5, precision = 82.52 % , error = 2433869281.23\n",
      "loss = ls, n_estimators = 500, learning_rate = 0.7, precision = 83.71 % , error = 2267591940.5\n",
      "loss = ls, n_estimators = 1000, learning_rate = 0.3, precision = 84.14 % , error = 2208073058.99\n",
      "loss = ls, n_estimators = 1000, learning_rate = 0.5, precision = 86.49 % , error = 1880181066.69\n",
      "loss = ls, n_estimators = 1000, learning_rate = 0.7, precision = 87.37 % , error = 1758652439.85\n",
      "loss = ls, n_estimators = 2000, learning_rate = 0.3, precision = 87.97 % , error = 1673928315.51\n",
      "loss = ls, n_estimators = 2000, learning_rate = 0.5, precision = 90.15 % , error = 1370809270.3\n",
      "loss = ls, n_estimators = 2000, learning_rate = 0.7, precision = 90.96 % , error = 1258596481.19\n",
      "loss = ls, n_estimators = 5000, learning_rate = 0.3, precision = 92.57 % , error = 1034639532.82\n",
      "loss = ls, n_estimators = 5000, learning_rate = 0.5, precision = 94.09 % , error = 822793927.401\n",
      "loss = ls, n_estimators = 5000, learning_rate = 0.7, precision = 94.72 % , error = 734618824.22\n",
      "loss = lad, n_estimators = 300, learning_rate = 0.3, precision = 72.55 % , error = 3821011688.77\n",
      "loss = lad, n_estimators = 300, learning_rate = 0.5, precision = 73.32 % , error = 3714273413.95\n",
      "loss = lad, n_estimators = 300, learning_rate = 0.7, precision = 73.52 % , error = 3685602704.73\n",
      "loss = lad, n_estimators = 500, learning_rate = 0.3, precision = 72.68 % , error = 3803314326.87\n",
      "loss = lad, n_estimators = 500, learning_rate = 0.5, precision = 73.13 % , error = 3740899132.25\n",
      "loss = lad, n_estimators = 500, learning_rate = 0.7, precision = 73.25 % , error = 3724052540.73\n",
      "loss = lad, n_estimators = 1000, learning_rate = 0.3, precision = 72.99 % , error = 3759817995.54\n",
      "loss = lad, n_estimators = 1000, learning_rate = 0.5, precision = 73.13 % , error = 3740832927.11\n",
      "loss = lad, n_estimators = 1000, learning_rate = 0.7, precision = 73.28 % , error = 3718763975.94\n",
      "loss = lad, n_estimators = 2000, learning_rate = 0.3, precision = 72.55 % , error = 3821011688.71\n",
      "loss = lad, n_estimators = 2000, learning_rate = 0.5, precision = 73.15 % , error = 3737698745.37\n",
      "loss = lad, n_estimators = 2000, learning_rate = 0.7, precision = 73.28 % , error = 3718794229.88\n",
      "loss = lad, n_estimators = 5000, learning_rate = 0.3, precision = 72.66 % , error = 3806157980.64\n",
      "loss = lad, n_estimators = 5000, learning_rate = 0.5, precision = 73.44 % , error = 3696846178.89\n",
      "loss = lad, n_estimators = 5000, learning_rate = 0.7, precision = 73.38 % , error = 3706150677.56\n",
      "loss = huber, n_estimators = 300, learning_rate = 0.3, precision = 75.69 % , error = 3384354877.27\n",
      "loss = huber, n_estimators = 300, learning_rate = 0.5, precision = 77.34 % , error = 3154029841.51\n",
      "loss = huber, n_estimators = 300, learning_rate = 0.7, precision = 78.31 % , error = 3018931377.4\n",
      "loss = huber, n_estimators = 500, learning_rate = 0.3, precision = 77.24 % , error = 3167666555.35\n",
      "loss = huber, n_estimators = 500, learning_rate = 0.5, precision = 78.94 % , error = 2931246072.49\n",
      "loss = huber, n_estimators = 500, learning_rate = 0.7, precision = 80.58 % , error = 2702666864.41\n",
      "loss = huber, n_estimators = 1000, learning_rate = 0.3, precision = 79.89 % , error = 2798629087.73\n",
      "loss = huber, n_estimators = 1000, learning_rate = 0.5, precision = 81.61 % , error = 2559595465.67\n",
      "loss = huber, n_estimators = 1000, learning_rate = 0.7, precision = 83.26 % , error = 2329765583.88\n",
      "loss = huber, n_estimators = 2000, learning_rate = 0.3, precision = 83.19 % , error = 2339553186.48\n",
      "loss = huber, n_estimators = 2000, learning_rate = 0.5, precision = 85.31 % , error = 2044825185.12\n",
      "loss = huber, n_estimators = 2000, learning_rate = 0.7, precision = 86.63 % , error = 1861655866.35\n",
      "loss = huber, n_estimators = 5000, learning_rate = 0.3, precision = 87.61 % , error = 1724749078.89\n",
      "loss = huber, n_estimators = 5000, learning_rate = 0.5, precision = 89.81 % , error = 1418225934.85\n",
      "loss = huber, n_estimators = 5000, learning_rate = 0.7, precision = 90.39 % , error = 1337110463.31\n",
      "loss = quantile, n_estimators = 300, learning_rate = 0.3, precision = 44.11 % , error = 7779450732.61\n",
      "loss = quantile, n_estimators = 300, learning_rate = 0.5, precision = 47.36 % , error = 7327818561.72\n",
      "loss = quantile, n_estimators = 300, learning_rate = 0.7, precision = 40.92 % , error = 8224533929.33\n",
      "loss = quantile, n_estimators = 500, learning_rate = 0.3, precision = 44.11 % , error = 7779450732.61\n",
      "loss = quantile, n_estimators = 500, learning_rate = 0.5, precision = 47.56 % , error = 7299764341.83\n",
      "loss = quantile, n_estimators = 500, learning_rate = 0.7, precision = 40.68 % , error = 8257791419.05\n",
      "loss = quantile, n_estimators = 1000, learning_rate = 0.3, precision = 44.11 % , error = 7779450732.61\n",
      "loss = quantile, n_estimators = 1000, learning_rate = 0.5, precision = 47.68 % , error = 7283285119.8\n",
      "loss = quantile, n_estimators = 1000, learning_rate = 0.7, precision = 41.19 % , error = 8185764622.76\n",
      "loss = quantile, n_estimators = 2000, learning_rate = 0.3, precision = 44.11 % , error = 7779450732.61\n",
      "loss = quantile, n_estimators = 2000, learning_rate = 0.5, precision = 47.81 % , error = 7264306528.52\n",
      "loss = quantile, n_estimators = 2000, learning_rate = 0.7, precision = 41.83 % , error = 8097080891.36\n",
      "loss = quantile, n_estimators = 5000, learning_rate = 0.3, precision = 44.11 % , error = 7779450732.61\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(\"loss = {}, n_estimators = {}, learning_rate = {}, precision = {:.2f} % , error = {}\"\\\n",
    "          .format(r[0],r[1],r[2],r[3],r[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor precision = loss = ls, n_estimators = 5000, learning_rate = 0.7, precision = 94.72 % , error = 734618824.22\n",
      "Menor error = loss = ls, n_estimators = 5000, learning_rate = 0.7, precision = 94.72 % , error = 734618824.22\n"
     ]
    }
   ],
   "source": [
    "min_error = float('inf')\n",
    "max_precision = 0\n",
    "tupla_min_error = ()\n",
    "tupla_max_precision = ()\n",
    "for r in res:\n",
    "    if r[4] < min_error:\n",
    "        min_error = r[4]\n",
    "        tupla_min_error = r\n",
    "    if r[3] > max_precision:\n",
    "        max_precision = r[3]\n",
    "        tupla_max_precision = r\n",
    "        \n",
    "print(\"Mayor precision = loss = {}, n_estimators = {}, learning_rate = {}, precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_max_precision[0],tupla_max_precision[1],tupla_max_precision[2],tupla_max_precision[3],tupla_max_precision[4]))\n",
    "print(\"Menor error = loss = {}, n_estimators = {}, learning_rate = {}, precision = {:.2f} % , error = {}\".\\\n",
    "              format(tupla_min_error[0],tupla_min_error[1],tupla_min_error[2],tupla_min_error[3],tupla_min_error[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 97.27 % , error = 379888832.31303084\n"
     ]
    }
   ],
   "source": [
    "l = 'ls'\n",
    "n = 5000\n",
    "d = 5\n",
    "lr = 0.7\n",
    "\n",
    "gradient = GradientBoostingRegressor(loss = l, n_estimators = n, max_depth = d,\\\n",
    "                                     learning_rate = lr)\n",
    "gradient.fit(set_entrenamiento_datos,set_entrenamiento_resultado)\n",
    "set_pruebas.loc[:,'resultado'] = set_pruebas.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)\n",
    "precision = gradient.score(set_pruebas.loc[:,columnas],set_pruebas.price_aprox_usd) * 100\n",
    "error = mean_squared_error(set_pruebas.price_aprox_usd,set_pruebas.resultado)\n",
    "print(\"Precision = {:.2f} % , error = {}\".format(precision, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculo con los verdaderos datos a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analizar = pd.read_csv(\"../properati_dataset_modificado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas = ['superficie','lat', 'lon','property_type_encoded','seguridad','gimnasio', 'aire', 'pileta', 'cochera']\n",
    "analisis = svd.transform(analizar.loc[:,columnas])\n",
    "analisis = pd.DataFrame(analisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.416600e+04\n",
       "mean     3.301517e+02\n",
       "std      2.023766e+04\n",
       "min      4.621164e+01\n",
       "25%      8.041788e+01\n",
       "50%      1.004089e+02\n",
       "75%      1.568249e+02\n",
       "max      2.405964e+06\n",
       "Name: SVD 1, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar.loc[:,'SVD 1'] = analisis.loc[:,0]\n",
    "analizar.loc[:,'SVD 2'] = analisis.loc[:,1]\n",
    "analizar['SVD 1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnas += ['SVD 1', 'SVD 2']\n",
    "analizar.loc[:,'price_usd'] = analizar.loc[:,columnas].apply(lambda x: gradient.predict([x])[0],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.416600e+04\n",
       "mean     2.004579e+05\n",
       "std      1.627526e+05\n",
       "min      6.038661e+01\n",
       "25%      9.506098e+04\n",
       "50%      1.478676e+05\n",
       "75%      2.557272e+05\n",
       "max      1.352245e+06\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analizar.loc[:, 'price_usd'] = analizar.loc[:, 'price_usd'].apply(lambda x: abs(x))\n",
    "analizar.price_usd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultado = analizar.loc[:,['id','price_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultado.to_csv('resultados/Gradient_Boosting_menos_datos_svd_agregada.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algoritmos/Gradient_Boosting_svd_agregada.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gradient, 'algoritmos/Gradient_Boosting_svd_agregada.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
